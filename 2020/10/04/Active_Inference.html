<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Bayesian Inference of the brain and the derivation of the Free Energy Principle | Reinforcement Learning and Active Inference</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Bayesian Inference of the brain and the derivation of the Free Energy Principle" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Notes on RL &amp; Active Inference." />
<meta property="og:description" content="Notes on RL &amp; Active Inference." />
<link rel="canonical" href="https://pianopwner.github.io/notes/2020/10/04/Active_Inference.html" />
<meta property="og:url" content="https://pianopwner.github.io/notes/2020/10/04/Active_Inference.html" />
<meta property="og:site_name" content="Reinforcement Learning and Active Inference" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-04T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://pianopwner.github.io/notes/2020/10/04/Active_Inference.html","@type":"BlogPosting","headline":"Bayesian Inference of the brain and the derivation of the Free Energy Principle","dateModified":"2020-10-04T00:00:00-05:00","datePublished":"2020-10-04T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://pianopwner.github.io/notes/2020/10/04/Active_Inference.html"},"description":"Notes on RL &amp; Active Inference.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://pianopwner.github.io/notes/feed.xml" title="Reinforcement Learning and Active Inference" /><link rel="shortcut icon" type="image/x-icon" href="/notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/notes/">Reinforcement Learning and Active Inference</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/notes/about/">About Me</a><a class="page-link" href="/notes/search/">Search</a><a class="page-link" href="/notes/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Bayesian Inference of the brain and the derivation of the Free Energy Principle</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-04T00:00:00-05:00" itemprop="datePublished">
        Oct 4, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      10 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/pianopwner/notes/tree/master/_notebooks/2020-10-04-Active_Inference.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/notes/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/pianopwner/notes/master?filepath=_notebooks%2F2020-10-04-Active_Inference.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/notes/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/pianopwner/notes/blob/master/_notebooks/2020-10-04-Active_Inference.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/notes/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-04-Active_Inference.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\DeclareMathOperator*{\argmax}{arg\,max}$
The idea of the Free Energy Principle has its foundations in Bayesian Inference, specificall Variational Bayesion Methods, as well as the theory of predictive coding. 'Inference' in this case means infering the probability of a hidden state (or hypothesis) given an observation (evidence). This brings us to Bayes' formula:</p>
<p><strong>$p(H|E) = \frac{p(E|H)p(H)}{p(E)}$</strong></p>
<p>To see how this equation works in practice, let's introduce an example, taken from <a href="https://www.sciencedirect.com/science/article/pii/S0022249615000759">Bogacz's paper</a>.</p>
<p>Consider a simple life form with one photo-sensitive receptor. This life form scuttles around trying to determine the size of objects around it based on reflective light. Let the size of an object = $v$. This simple life form has a difficult time perceiving the correct light intesnity as its photo-receptor provides a noisy input. Therefore when the size of an object is $v$, the organism perceives a normally distributed light intensity $p(u|v) =N(g(v), \sum_u)$ where $g$ is a mapping of size to light intensity approximated by the organism. For now let $g(v) = v^2$. Addtionally, the organism has a prior assumption on the sizes of objects around it. For simplicity, let's imagine this prior as a normal distribution with mean $v_p$ and variance $\sum_p$. Therefore $p(v) = N(v_p,\sum_p)$. We now have all the components necessary to construct Bayes' theorem with $u$ as the evidence and $v$ as the hypothesis:</p>
<p><strong>$p(v|u) = \frac{p(u|v)p(v)}{p(u)}$</strong></p>
<p>This, however, presents a problem. Calculating the numerator is easy, as it is described by the multiplication of two known normal distributions (stated above). The denominator, however, by the law of total probability, is expressed as: $p(u) = \int p(u|v)p(v)dv$. In many scenarios, these integrals are intractable, and are especially impossible for organisms utilising neuronal connections for calculation. Therefore, the posterior distribution $p(v|u)$ needs to be calculated some other way. This is where Variational Bayes comes in. We might not be able to calculate the exact posterior, but we can try approximate it. To start, lets just consider a very coarse approximation of determining the mode of the posterior. In the case of our organism, the mode is important as it representsthe most likely $v$ given the observed $u$ and the prior. It is reasonable to think that it is realistic and useful for organisms to only entertain most likely hypotheses rather than the probability of all possible hypotheses. Therefore we want to find the value of $v$ which is the maximum point of the posterior. Let this $v = \phi = \argmax_v p(v|u)$. The important part about estimating just one value of $v$ is that the denominator $p(u) = \int p(u|v)p(v)$ does not depend on $\phi$ and is constant for any value $v$ of which we want to calculate the probability. Finding $\phi$ then simply becomes a case of finding the value of $v$ which maximises the numerator: $p(u|v)p(v)$ putting this all together, we have:</p>
<p>$max_vp(v|u) = p(u|\phi)p(\phi)$</p>
<p>Now from here all we need do is iteratively determine $\phi$. This can be achieved via gradient ascent. We take the logarithm of the numerator because the maximum of it is the same as the maximum of $p(u|v)p(v)$ and is an easier function to work with as calculating $p(u|v)p(v)$ involves exponentiation:</p>
<p>$F = ln(p(u|v)p(v))$</p>
<p>$= ln(pu|v) + ln p(v)$</p>
<p>$= ln \bigg[\frac{1}{\sqrt{2\pi\Sigma_p}}exp\bigg(-\frac{(\phi - v_p)^2}{2\Sigma_p}\bigg)\bigg] + ln \bigg[\frac{1}{\sqrt{2\pi\Sigma_u}}exp\bigg(-\frac{(u - g(\phi))^2}{2\Sigma_u}\bigg)\bigg]$</p>
<p>$...$</p>
<p>$...$</p>
<p>$ = \frac{1}{2}\bigg(-\frac{(\phi - v_p)^2}{\Sigma_p} - \frac{(u-g(\phi))^2}{\Sigma_u}\bigg) + C$</p>
<p>In the last line, all the constant terms not involving $\phi$ have been incorporated into a constant $C$ as they will dissapear when the derivative is taken:</p>
<p>$ \frac{\partial F}{\partial \phi} = \frac{v_p - \phi}{\Sigma_p} + \frac{u-g(\phi)}{\Sigma_u}g'(\phi)$</p>
<p>With this equation we can pefrom gradient ascent until $\theta$ converges on a value. This will be the value which maximises $F$ and therefore maximises $p(v|u)$. 
Looking at the form of the equation, it is evident that the gradient of $F$ is being influenced in two different ways. One by how much the approximated hypothesis $\phi$ is different from the prior mean hypothesis and the other by how different the observation, $u$, is from the expected observation given the approxmated hypothesis $g(\phi)$. There seems to be a tradeoff happening here. The prior and the <a href="https://en.wikipedia.org/wiki/Likelihood_function">likelihood</a> are each pulling the posterior toward their mean values, with it ultimately being a weighted average between the two. The weighting here is exactly determined by the variance of the two terms respectively, with higher variance resulting in a less 'reliable' contribution to the posterior. Ths makes sense, as the more noisy the prior or observation is, the less one would want it to contribute to the inference of a posterior hypothesis.</p>
<p>To frame this in terms of neuronal activity, let us denote these two terms in the derviative of $F$ as:</p>
<p>$\epsilon_p = \frac{\phi - v_p}{\Sigma_p}$
$\epsilon_u = \frac{u - g(\phi)}{\Sigma_u}$</p>
<p>As alluded to above, these can be viewed as <strong>weighted prediction errors</strong> and could be realised in a simple neuronal structure as follows:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/notes/images/copied_from_nb/my_icons/simple_network.png" alt="" style="max-width: 400px" />
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here lines with arrows denote excitatory connections while lines with circles denote inhibitory connections. The circular connection between the prediction error nodes and the inference node allows for iterative update of all three as the maximum posterior is calculated. The update equations of the three inner nodes are as follows:</p>
<p>$\phi_{new} = \phi_{old} + a(\epsilon_ug'(\phi) - \epsilon_p)$</p>
<p>$\epsilon_{u_{new}} = \epsilon_{u_{old}} + a(u - g(\phi_{new}) - \epsilon_{u_{old}}\Sigma_u)$</p>
<p>$\epsilon_{p_{new}} = \epsilon_{p_{old}} + a(\phi_{new} - v_p - \epsilon_{p_{old}}\Sigma_p)$</p>
<p>where $0&lt;a&lt;1$ is some constant to allow for better convergence. Note that in the update equation for $\phi$, the quantity from the excitatory 'evidence' neuron $\epsilon_ug'(\phi)$ is being added, while the quantity from the inhibitory 'prior' neuron $\epsilon_p$ is being subtracted. This exemplified the two componenets 'pulling' the posterior in different directions as stated above. 
Also note that the error neurons are being self-inhibited by their respective variances, which represent the weighting on the components used in calculating the inferenced hypothesis.</p>
<p>The next step for the organism would be to shift its prior and likelihood calculation so as to better represent the new observation. In this case, it would mean changing the $v_p, \Sigma_p$ and $\Sigma_u$ as well as sometimes the transformation function $g$. Essentailly, the organsim would like to maximise $p(u)$ on average. If it is constantly inferring hypotheses that it gives little prior probability to, $p(v)$, and little likelihood to, $p(u|v)$ perhaps it should adjust the parameters that determine these two factors. In bayesian Inference, this is what model evidence is, referred to in frequentist statistics as marginal likelihood. However trying to maximise $p(u)$ once again leaves us with the problem of the intractable marginalisation: $p(u) = \int p(u|v)p(v)dv$. To avoid this we can turn to maximising a related and familiar expression: $p(u, \phi)$. At first glance it might not seem clear why maximising this term, rather the whole model evidence, is useful. Remember that $p(u)$ essentially represents a weighted average of all possible likelihoods. However given that we are not necessarily attempting to calculate the entire posterior distribution, rather just one point of the posterior, it is reasonable to only care about maximising model evidence with respect to this point. Note that $p(u,\phi) = p(u|\phi)p(\phi) = F$. Therefore by maximising $F$ with respect to the various parameters mentioned above will maximise the model evidence for the point of maximum likelihood, $\phi$. The update to these parameters would therefore be proportional to the derivative of $F$ with respect to each:</p>
<p>$\frac{\partial F}{\partial v_p} = \frac{\phi - v_p}{\Sigma_p}$</p>
<p>$\frac{\partial F}{\partial \Sigma_p} = \frac{1}{2}\bigg(\frac{(\phi - v_p)^2}{\Sigma_p^2} - \frac{1}{\Sigma_p}\bigg)$</p>
<p>$\frac{\partial F}{\partial \Sigma_u} = \frac{1}{2}\bigg(\frac{(u - g(\phi))^2}{\Sigma_u^2} - \frac{1}{\Sigma_u}\bigg)$</p>
<p>Additionally, the translation, $g$ may be incorrect. In its most complex form, updating this function would require the approximating power of a separate neural network. In its simplest form, the function form is static but weighted by a parameter $\theta$ which can represent the strength of the connection between the neurons which pass the translated data - in this case between the neurons computing $\epsilon_u$ and $\phi$ (see picture above). The update update to this weighting would therefore be:
$\frac{\partial F}{\partial \theta} = \epsilon_u\phi$</p>
<h3 id="Free-Energy">Free Energy<a class="anchor-link" href="#Free-Energy"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All this calculation has been for the purpose of two main things: Approximating the posterior distribution and maximising model evidence. We will now see that this can be approached from another angle.</p>
<p>Consider the goal of approximating the posterior. For the sake of simplicity, and we will continue on that vein, but this time treating that single value as a distribution, specifically a delta distribution with all its mass concentrated at one point which we will denote as $\phi$ (therefore has a 0 probability at every other point). This fits well with what we did above, however it is important to remember that we could use another known distribution, such as the normal, to approximate the posterior, however for now we will stick with the delta distribution.</p>
<p>Let $q(v)$ = the distribution to approximate the posterior (in this example remember q(v) is the delta distribution)
We can take the KL-divergence between the two distributions to measure their similarity (with a KL-divergence of 0 meaning they are identical):</p>
<p>$KL(q(v), p(v|u)) = \int q(v)ln\frac{q(v)}{p(v|u)}dv$</p>
<p>substituting in the definition that $p(v|u) = \frac{p(u,v)}{p(u)}$ we have:</p>
<p>$KL(q(v), p(v|u)) = \int q(v)ln\frac{q(v)p(u)}{p(v,u)}dv$</p>
<p>$= \int q(v)ln\frac{q(v)}{p(v,u)}dv + \int q(v)dvlnp(u)$</p>
<p>$= \int q(v)ln\frac{q(v)}{p(v,u)}dv + lnp(u)$</p>
<p>Going from the second to the third line we note that the integral of $q(v)$ is 1 and $lnp(u)$ is not a function of $v$</p>
<p>Let $F = \int q(v)ln\frac{q(v)}{p(v,u)}dv$. This term is known as negative Free Energy and is related to the KL-divergence by:</p>
<p>$KL(q(v), p(v|u)) = -F + lnp(u)$</p>
<p>Now because $lnp(u)$ does not depend on $q$, the minimisation of the KL divergence between the two distributions can be achieved b maximising $F$. In this case, the value of $\phi$ that minimises the distance between $q(v)$ and $p(v|u)$ is the value of $\phi$ which maximises $F$. To go full cicle, we will evaluate $F$ a little more:</p>
<p>$F = \int q(v)ln\frac{q(v)}{p(v,u)}dv$</p>
<p>$  = \int q(v)lnp(u,v)dv - \int q(v)lnp(v)dv$</p>
<p>Using the property of the delta function which states that for $\delta(x)$ with center $\phi$, for any function $h(x)$, the integral of $\delta(x)h(x)$ is equal to $h(\phi)$. Therefore:</p>
<p>$F = lnp(u,\phi) + C$</p>
<p>We can change the second integral in the expression to a constant as it does not depend on $\phi$ and will cancel when we take the derivative.
This expression is exactly the same as $F$ calculated in the previous section, and it should be, as approxmating a distribution with the delta distribution is the same as approximating it with a single point ($\phi$). 
Also note that $lnp(u) = F + KL(q(v), p(v|u))$. 
Since the KL-divergence is non-negative, the minimum the log model evidence can be is $F$. Therefore $F$ acts as a lower bound to model evidence, and maximising it via model parameters (as we did in the previous section) maximises the lower bound on model evidence.</p>
<p>Thus maximising $F$ serves to both maximise the approximate distribution, and optimise model parameters.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/notes/2020/10/04/Active_Inference.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/notes/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/notes/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Notes on RL &amp; Active Inference.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"></ul>
</div>

  </div>

</footer>
</body>

</html>
